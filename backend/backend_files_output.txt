=== VIEWING BACKEND FILES ===

1. Main application file:
------------------------
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from app.api import experts, search, marketplace, matching
from app.api import test_debug
from app.utils.database import init_db
import traceback
import uuid
import os

app = FastAPI(title="Expert Finder API", version="2.0.0")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:3001", 
        "http://localhost:3002",
        "http://localhost:3003",
        "https://web-production-80694.up.railway.app", 
        "https://expert-finder.up.railway.app",
        "https://expert-finder-production.up.railway.app",
        "*"  # Allow all origins during development
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add exception handler for better error logging
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """Global exception handler to log all errors"""
    error_id = str(uuid.uuid4())[:8]
    
    # Log the full error
    print(f"\n{'='*60}")
    print(f"ERROR ID: {error_id}")
    print(f"Endpoint: {request.method} {request.url.path}")
    print(f"Error Type: {type(exc).__name__}")
    print(f"Error Message: {str(exc)}")
    print(f"\nFull Traceback:")
    traceback.print_exc()
    print(f"{'='*60}\n")
    
    # Return user-friendly error
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "error_id": error_id,
            "message": str(exc) if os.getenv("DEBUG", "false").lower() == "true" else "An error occurred",
            "type": type(exc).__name__
        }
    )

# Include routers
app.include_router(experts.router)
app.include_router(search.router)
app.include_router(marketplace.router)
app.include_router(matching.router)
app.include_router(test_debug.router)

@app.on_event("startup")
async def startup_event():
    """Initialize the database on startup"""
    init_db()

@app.get("/")
async def root():
    """Root endpoint"""
    return {"message": "Expert Finder API v2.0.0", "status": "online"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "version": "2.0.0",
        "service": "expert-finder-api"
    }

2. Search Service:
-----------------
"""Search service implementation"""
from typing import List, Dict, Any, Optional
import os
import httpx
import json
from app.agents.web_search_agent import web_search_agent
from app.services.enhanced_search_service import enhanced_search_service

class SearchService:
    """Service for searching experts online"""
    
    def __init__(self):
        self.google_api_key = os.getenv("GOOGLE_API_KEY", "")
        self.google_cse_id = os.getenv("GOOGLE_CSE_ID", "")
        self.use_google_api = bool(self.google_api_key and self.google_cse_id)
    
    async def search(
        self, 
        query: str,
        source: str = "all",
        limit: int = 10,
        offset: int = 0,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Search for experts online"""
        
        if not query:
            return {"experts": [], "total": 0}
        
        experts = []
        
        # Use Google Custom Search API if available
        if self.use_google_api:
            experts = await self._google_custom_search(query, limit)
        else:
            # Use web scraping agent as fallback
            search_results = web_search_agent.search_google(query, limit)
            
            # Convert search results to expert format
            for idx, result in enumerate(search_results):
                expert_data = {
                    "id": f"web_{idx}",
                    "name": result.get('title', '').split(' - ')[0],
                    "title": result.get('snippet', '')[:100],
                    "source": "Google Search",
                    "profile_url": result.get('url', ''),
                    "skills": self._extract_skills_from_text(result.get('snippet', '')),
                    "bio": result.get('snippet', ''),
                    "match_score": 85 - (idx * 5)  # Decreasing relevance
                }
                experts.append(expert_data)
        
        # If no results from web search, provide mock data for demo
        if not experts:
            experts = await self._get_mock_experts(query)
        
        # Apply pagination
        total = len(experts)
        experts = experts[offset:offset + limit]
        
        return {
            "experts": experts,
            "total": total,
            "query": query,
            "sources_searched": ["Google", "LinkedIn", "Professional Networks"]
        }
    
    async def _google_custom_search(self, query: str, limit: int) -> List[Dict]:
        """Use Google Custom Search API"""
        try:
            # Build search query
            search_query = f"{query} expert consultant professional LinkedIn"
            
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    "https://www.googleapis.com/customsearch/v1",
                    params={
                        "key": self.google_api_key,
                        "cx": self.google_cse_id,
                        "q": search_query,
                        "num": min(limit, 10)  # Google limits to 10 per request
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    experts = []
                    
                    for idx, item in enumerate(data.get('items', [])):
                        expert = {
                            "id": f"google_{idx}",
                            "name": self._extract_name_from_title(item.get('title', '')),
                            "title": item.get('snippet', '')[:100],
                            "bio": item.get('snippet', ''),
                            "source": "Google",
                            "profile_url": item.get('link', ''),
                            "organization": item.get('displayLink', '').replace('www.', '').split('.')[0].title(),
                            "skills": self._extract_skills_from_text(item.get('snippet', '')),
                            "match_score": 90 - (idx * 5)
                        }
                        experts.append(expert)
                    
                    return experts
                else:
                    print(f"Google API error: {response.status_code}")
                    return []
                    
        except Exception as e:
            print(f"Error calling Google API: {e}")
            return []
    
    def _extract_name_from_title(self, title: str) -> str:
        """Extract name from search result title"""
        # Common patterns: "John Doe - Title", "John Doe | Company"
        if ' - ' in title:
            return title.split(' - ')[0].strip()
        elif ' | ' in title:
            return title.split(' | ')[0].strip()
        elif ' – ' in title:
            return title.split(' – ')[0].strip()
        return title.strip()
    
    def _extract_skills_from_text(self, text: str) -> List[str]:
        """Extract potential skills from text"""
        # Common skill keywords
        skill_keywords = [
            "AI", "Machine Learning", "Python", "Data Science", "Deep Learning",
            "TensorFlow", "PyTorch", "AWS", "Cloud", "DevOps", "Kubernetes",
            "React", "JavaScript", "Node.js", "SQL", "NoSQL", "Blockchain",
            "Cybersecurity", "Analytics", "Consulting", "Strategy"
        ]
        
        found_skills = []
        text_lower = text.lower()
        
        for skill in skill_keywords:
            if skill.lower() in text_lower:
                found_skills.append(skill)
        
        return found_skills[:5]  # Limit to 5 skills
    
    async def _get_mock_experts(self, query: str) -> List[Dict]:
        """Get mock experts for demo purposes"""
        mock_experts = []
        
        if "AI" in query.upper() or "machine learning" in query.lower():
            mock_experts = [
                {
                    "id": "mock_1",
                    "name": "Dr. Sarah Chen",
                    "title": "AI Research Scientist & Consultant",
                    "organization": "Stanford AI Lab",
                    "location": "San Francisco, CA",
                    "bio": "Leading AI researcher with 15+ years experience in machine learning and neural networks. Specializes in NLP and computer vision applications.",
                    "skills": ["Machine Learning", "Deep Learning", "Python", "TensorFlow", "NLP"],
                    "source": "LinkedIn",
                    "profile_url": "https://www.linkedin.com/in/sarahchen",
                    "match_score": 95
                },
                {
                    "id": "mock_2",
                    "name": "Prof. Michael Zhang",
                    "title": "ML Engineering Expert",
                    "organization": "MIT CSAIL",
                    "location": "Boston, MA", 
                    "bio": "Expert in production ML systems, MLOps, and scalable AI infrastructure. Author of several influential papers on distributed learning.",
                    "skills": ["MLOps", "Kubernetes", "Python", "Cloud Architecture", "AI"],
                    "source": "University Profile",
                    "profile_url": "https://www.csail.mit.edu/person/michael-zhang",
                    "match_score": 90
                }
            ]
        elif "python" in query.lower():
            mock_experts = [
                {
                    "id": "mock_3",
                    "name": "Alex Rodriguez",
                    "title": "Senior Python Developer & Architect",
                    "organization": "Tech Consulting Inc",
                    "location": "New York, NY",
                    "bio": "15+ years Python development. Expert in Django, FastAPI, and scalable microservices. Regular PyCon speaker.",
                    "skills": ["Python", "Django", "FastAPI", "Microservices", "AWS"],
                    "source": "Professional Network",
                    "profile_url": "#",
                    "match_score": 92
                }
            ]
        
        return mock_experts
    
    async def vector_search(
        self,
        query: str,
        limit: int = 10,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Vector similarity search"""
        return await self.search(query=query, limit=limit, filters=filters)
    
    async def get_suggestions(self, query: str) -> List[str]:
        """Get search suggestions"""
        if not query or len(query) < 2:
            return []
        
        suggestions = [
            "AI expert",
            "Machine Learning consultant",
            "Python developer",
            "Data Science expert",
            "Cloud architect",
            "Blockchain expert",
            "Cybersecurity consultant",
            "DevOps engineer",
            "React developer",
            "Mobile app expert"
        ]
        
        return [s for s in suggestions if query.lower() in s.lower()][:5]
    
    async def get_trending_searches(self, limit: int = 10) -> List[str]:
        """Get trending searches"""
        return [
            "AI consultant",
            "Machine Learning expert",
            "ChatGPT integration expert",
            "Python developer",
            "Cloud migration specialist",
            "Blockchain developer",
            "Data Science consultant"
        ][:limit]

# Create singleton instance
search_service = SearchService()

3. Enhanced Search Service:
--------------------------
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import re
from bs4 import BeautifulSoup

class EnhancedSearchService:
    def __init__(self):
        self.session = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def search_expert_details(self, expert_name: str, expertise: str) -> Dict[str, Any]:
        """Search for comprehensive expert information"""
        tasks = [
            self.search_contact_info(expert_name, expertise),
            self.search_images(expert_name, expertise),
            self.search_credentials(expert_name),
            self.search_social_proof(expert_name),
            self.extract_linkedin_info(expert_name, expertise)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return {
            "contacts": results[0] if not isinstance(results[0], Exception) else [],
            "images": results[1] if not isinstance(results[1], Exception) else [],
            "credentials": results[2] if not isinstance(results[2], Exception) else [],
            "social_proof": results[3] if not isinstance(results[3], Exception) else [],
            "linkedin_data": results[4] if not isinstance(results[4], Exception) else {}
        }
    
    async def search_contact_info(self, name: str, expertise: str) -> List[Dict]:
        """Search for contact information"""
        # Simulate search - in production, use actual APIs
        contacts = []
        
        # Search patterns
        search_queries = [
            f'"{name}" {expertise} email contact',
            f'"{name}" {expertise} "book consultation"',
            f'"{name}" {expertise} linkedin profile'
        ]
        
        # Simulated results (replace with actual API calls)
        if "Matthew Hussey" in name:
            contacts.extend([
                {
                    "method": "website",
                    "value": "https://www.matthewhussey.com",
                    "is_verified": True,
                    "is_public": True,
                    "preferred": True
                },
                {
                    "method": "calendar",
                    "value": "https://calendly.com/matthewhussey",
                    "is_verified": True,
                    "is_public": True
                },
                {
                    "method": "linkedin",
                    "value": "https://linkedin.com/in/matthewhussey",
                    "is_verified": True,
                    "is_public": True
                }
            ])
        
        return contacts
    
    async def search_images(self, name: str, expertise: str) -> List[Dict]:
        """Search for expert images"""
        images = []
        
        # Simulated image search results
        if "Matthew Hussey" in name:
            images.extend([
                {
                    "url": "https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=400",
                    "type": "profile",
                    "caption": "Professional headshot",
                    "source": "Official website",
                    "verified": True
                },
                {
                    "url": "https://images.unsplash.com/photo-1515378791036-0648a3ef77b2?w=600",
                    "type": "work_sample",
                    "caption": "Speaking at relationship conference",
                    "source": "TEDx Talk",
                    "verified": True
                },
                {
                    "url": "https://images.unsplash.com/photo-1522202176988-66273c2fd55f?w=600",
                    "type": "credential",
                    "caption": "Coaching certification ceremony",
                    "source": "ICF Certification",
                    "verified": True
                }
            ])
        
        return images
    
    async def search_credentials(self, name: str) -> List[Dict]:
        """Search for credentials and certifications"""
        credentials = []
        
        if "Matthew Hussey" in name:
            credentials.extend([
                {
                    "title": "Certified Life Coach",
                    "issuer": "International Coach Federation (ICF)",
                    "date": "2015-06-15",
                    "verification_url": "https://coachfederation.org/verify",
                    "image_url": "https://example.com/icf-badge.png"
                },
                {
                    "title": "Master Practitioner of NLP",
                    "issuer": "American Board of NLP",
                    "date": "2012-03-20",
                    "verification_url": "https://abnlp.org/verify"
                }
            ])
        
        return credentials
    
    async def search_social_proof(self, name: str) -> List[Dict]:
        """Search for ratings and reviews"""
        social_proof = []
        
        if "Matthew Hussey" in name:
            social_proof.extend([
                {
                    "platform": "Google",
                    "rating": 4.8,
                    "review_count": 1250,
                    "url": "https://g.page/matthewhussey"
                },
                {
                    "platform": "Trustpilot",
                    "rating": 4.7,
                    "review_count": 890,
                    "url": "https://trustpilot.com/matthewhussey"
                }
            ])
        
        return social_proof
    
    async def extract_linkedin_info(self, name: str, expertise: str) -> Dict:
        """Extract LinkedIn information"""
        # Simulated LinkedIn data
        if "Matthew Hussey" in name:
            return {
                "headline": "Relationship Expert | NYT Bestselling Author | Speaker",
                "followers": 125000,
                "connections": 500,
                "recommendations": 47,
                "profile_url": "https://linkedin.com/in/matthewhussey"
            }
        return {}

# Create service instance
enhanced_search_service = EnhancedSearchService()

4. Expert Service:
-----------------
from typing import List, Optional
from app.models.expert import Expert
from app.models.db_models import ExpertDB
from app.utils.database import get_collection, init_db
from app.utils.embeddings import embedding_generator
import uuid
from typing import Dict
from typing import Any

class ExpertService:
    def __init__(self):
        # Ensure database is initialized
        # init_db() - Moved to app startup
        self.linkedin_collection = get_collection("linkedin_experts")
        self.scholar_collection = get_collection("scholar_experts")
    
    def create_expert_text(self, expert: Expert) -> str:
        """Create searchable text from expert data"""
        parts = [
            expert.name,
            expert.title or "",
            expert.organization or "",
            expert.bio or "",
            " ".join(expert.skills),
            expert.location or ""
        ]
        return " ".join(filter(None, parts))
    
    def add_expert(self, expert: Expert, source: str = "linkedin"):
        """Add an expert to the database"""
        collection = self.linkedin_collection if source == "linkedin" else self.scholar_collection
        
        # Generate embedding
        text = self.create_expert_text(expert)
        embedding = embedding_generator.generate_embedding(text)
        
        # Add to collection
        collection.add(
            embeddings=[embedding],
            documents=[text],
            metadatas=[expert.dict()],
            ids=[expert.id]
        )
        
        return expert
    
    def search_experts(self, query: str, source: str = "all", limit: int = 10) -> List[Expert]:
        """Search for experts based on query"""
        results = []
        
        # Generate query embedding
        query_embedding = embedding_generator.generate_embedding(query)
        
        # Search in LinkedIn collection
        if source in ["all", "linkedin"]:
            try:
                linkedin_results = self.linkedin_collection.query(
                    query_embeddings=[query_embedding],
                    n_results=limit
                )
                if linkedin_results['metadatas'] and linkedin_results['metadatas'][0]:
                    for metadata in linkedin_results['metadatas'][0]:
                        expert = Expert(**metadata)
                        expert.source = "linkedin"
                        results.append(expert)
            except Exception as e:
                print(f"Error searching LinkedIn collection: {e}")
        
        # Search in Scholar collection
        if source in ["all", "scholar"]:
            try:
                scholar_results = self.scholar_collection.query(
                    query_embeddings=[query_embedding],
                    n_results=limit
                )
                if scholar_results['metadatas'] and scholar_results['metadatas'][0]:
                    for metadata in scholar_results['metadatas'][0]:
                        expert = Expert(**metadata)
                        expert.source = "scholar"
                        results.append(expert)
            except Exception as e:
                print(f"Error searching Scholar collection: {e}")
        
        # Calculate credibility scores
        results = self.calculate_credibility_scores(results)
        
        # Sort by credibility score
        results.sort(key=lambda x: x.credibility_score or 0, reverse=True)
        
        return results[:limit]
    
    def calculate_credibility_scores(self, experts: List[Expert]) -> List[Expert]:
        """Calculate credibility scores for experts"""
        if not experts:
            return experts
        
        # Simple scoring based on available data
        for expert in experts:
            score = 0
            
            # Experience years (max 20 points)
            if expert.experience_years:
                score += min(expert.experience_years, 20)
            
            # Education level (max 20 points)
            education_scores = {
                "PhD": 20,
                "Masters": 15,
                "Bachelors": 10,
                "Other": 5
            }
            score += education_scores.get(expert.education_level or "Other", 5)
            
            # Citations (max 30 points)
            if expert.citations:
                score += min(expert.citations / 100, 30)
            
            # Skills count (max 20 points)
            score += min(len(expert.skills) * 2, 20)
            
            # Has bio (10 points)
            if expert.bio:
                score += 10
            
            expert.credibility_score = min(score, 100)
        
        return experts

# Don't initialize the service at module level
# expert_service = ExpertService()  # Commented out to prevent init on import

# Add to existing ExpertService class
async def get_expert_with_details(self, expert_id: str) -> Dict[str, Any]:
    """Get expert with all enhanced details"""
    # Get basic expert info
    expert = await self.get_expert_by_id(expert_id)
    
    if expert:
        # Enhance with additional data
        async with enhanced_search_service as search:
            details = await search.search_expert_details(
                expert.get('name', ''),
                expert.get('expertise', '')
            )
            
            # Merge enhanced data
            expert.update({
                'contacts': details.get('contacts', []),
                'images': details.get('images', []),
                'credentials': details.get('credentials', []),
                'social_proof': details.get('social_proof', []),
                'linkedin_data': details.get('linkedin_data', {}),
                'available_now': True,  # Check actual availability
                'response_time': "within 24 hours",
                'consultation_types': ["video", "phone", "chat"],
                'verified_expert': True
            })
    
    return expert

async def search_experts_enhanced(self, query: str, category: str = None, limit: int = 20) -> List[Dict]:
    """Enhanced search with rich data"""
    # Get basic search results
    results = await self.search_experts(query, category, limit)
    
    # Enhance top results with additional data
    enhanced_results = []
    async with enhanced_search_service as search:
        for i, expert in enumerate(results[:5]):  # Enhance top 5 results
            details = await search.search_expert_details(
                expert.get('name', ''),
                query
            )
            
            expert.update({
                'contacts': details.get('contacts', [])[:3],  # Top 3 contacts
                'images': details.get('images', [])[:2],  # Top 2 images
                'social_proof': details.get('social_proof', []),
                'match_reasons': [
                    f"Expert in {query}",
                    f"{expert.get('experience_years', 5)}+ years experience",
                    "Highly rated by clients"
                ],
                'available_now': i % 2 == 0,  # Simulate availability
                'response_time': "within 2 hours" if i % 2 == 0 else "within 24 hours"
            })
            enhanced_results.append(expert)
    
    # Add remaining results without enhancement
    enhanced_results.extend(results[5:])
    
    return enhanced_results

5. API Routes:
--------------
Listing all route files:
total 48
drwxr-xr-x   9 James  staff   288  7  8 14:51 .
drwxr-xr-x  10 James  staff   320  7  7 23:31 ..
-rw-r--r--   1 James  staff     0  7  5 00:37 __init__.py
-rw-r--r--   1 James  staff  1171  7  5 00:37 enhanced_experts.py
-rw-r--r--   1 James  staff  2051  7  7 23:27 experts.py
-rw-r--r--   1 James  staff  2864  7  8 01:03 marketplace.py
-rw-r--r--   1 James  staff  3061  7  9 12:46 matching.py
-rw-r--r--   1 James  staff  2129  7  8 01:04 search.py
-rw-r--r--   1 James  staff  1904  7  5 00:37 test_debug.py

Expert routes:
"""Expert API endpoints"""
from fastapi import APIRouter, HTTPException, Depends
from typing import List, Optional
from app.models.expert import Expert, ExpertCreate, ExpertUpdate
from app.services.expert_service import ExpertService
from app.utils.database import get_db
from sqlalchemy.orm import Session

router = APIRouter(prefix="/api/experts", tags=["experts"])

# Initialize service
expert_service = ExpertService()

@router.get("/", response_model=List[Expert])
async def list_experts(
    skip: int = 0,
    limit: int = 100,
    skills: Optional[str] = None,
    location: Optional[str] = None
):
    """List all experts with optional filtering"""
    filters = {}
    if skills:
        filters["skills"] = skills.split(",")
    if location:
        filters["location"] = location
    
    experts = await expert_service.list_experts(skip=skip, limit=limit, filters=filters)
    return experts

@router.get("/{expert_id}", response_model=Expert)
async def get_expert(expert_id: str):
    """Get a specific expert by ID"""
    expert = await expert_service.get_expert(expert_id)
    if not expert:
        raise HTTPException(status_code=404, detail="Expert not found")
    return expert

@router.post("/", response_model=Expert)
async def create_expert(expert: ExpertCreate):
    """Create a new expert"""
    return await expert_service.create_expert(expert.dict())

@router.put("/{expert_id}", response_model=Expert)
async def update_expert(expert_id: str, expert: ExpertUpdate):
    """Update an expert"""
    updated_expert = await expert_service.update_expert(expert_id, expert.dict(exclude_unset=True))
    if not updated_expert:
        raise HTTPException(status_code=404, detail="Expert not found")
    return updated_expert

@router.delete("/{expert_id}")
async def delete_expert(expert_id: str):
    """Delete an expert"""
    success = await expert_service.delete_expert(expert_id)
    if not success:
        raise HTTPException(status_code=404, detail="Expert not found")
    return {"message": "Expert deleted successfully"}
Search routes:
"""Search API endpoints"""
from fastapi import APIRouter, HTTPException
from typing import List, Dict, Any, Optional
from app.models.schemas import SearchQuery, SearchResponse
from app.services.search_service import SearchService
from app.models.expert import Expert

router = APIRouter(prefix="/api/search", tags=["search"])

# Initialize service
search_service = SearchService()

@router.post("/", response_model=SearchResponse)
async def search_experts(query: SearchQuery):
    """Search for experts based on query and filters"""
    try:
        results = await search_service.search(
            query=query.query,
            source=query.source,
            limit=query.limit,
            offset=query.offset,
            filters=query.filters
        )
        
        return SearchResponse(
            results=results["experts"],
            total=results["total"],
            query=query.query,
            filters=query.filters
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/vector", response_model=SearchResponse)
async def vector_search(query: SearchQuery):
    """Vector similarity search for experts"""
    try:
        results = await search_service.vector_search(
            query=query.query,
            limit=query.limit,
            filters=query.filters
        )
        
        return SearchResponse(
            results=results["experts"],
            total=results["total"],
            query=query.query,
            filters=query.filters
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/suggestions")
async def get_search_suggestions(q: str):
    """Get search suggestions based on partial query"""
    if len(q) < 2:
        return {"suggestions": []}
    
    suggestions = await search_service.get_suggestions(q)
    return {"suggestions": suggestions}

@router.get("/trending")
async def get_trending_searches(limit: int = 10):
    """Get trending search terms"""
    trending = await search_service.get_trending_searches(limit)
    return {"trending": trending}

6. Expert Model:
---------------
"""Expert model definitions"""
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
from enum import Enum

class ContactMethod(str, Enum):
    EMAIL = "email"
    PHONE = "phone"
    LINKEDIN = "linkedin"
    WEBSITE = "website"

class ExpertBase(BaseModel):
    name: str
    title: Optional[str] = None
    email: Optional[str] = None
    location: Optional[str] = None
    organization: Optional[str] = None
    bio: Optional[str] = None
    skills: List[str] = []
    experience: List[Dict[str, Any]] = []
    links: Dict[str, str] = {}

class ExpertCreate(ExpertBase):
    pass

class ExpertUpdate(BaseModel):
    name: Optional[str] = None
    title: Optional[str] = None
    email: Optional[str] = None
    location: Optional[str] = None
    organization: Optional[str] = None
    bio: Optional[str] = None
    skills: Optional[List[str]] = None
    experience: Optional[List[Dict[str, Any]]] = None
    links: Optional[Dict[str, str]] = None

class Expert(ExpertBase):
    id: str
    created_at: datetime
    updated_at: datetime
    
    # Additional fields for enhanced features
    rating: Optional[float] = None
    total_projects: Optional[int] = 0
    verified: bool = False
    availability_status: Optional[str] = None
    rate: Optional[Dict[str, Any]] = None  # {"amount": 150, "currency": "USD", "per": "hour"}
    languages: List[str] = []
    timezone: Optional[str] = None
    
    class Config:
        from_attributes = True

class ExpertSearchResult(BaseModel):
    expert: Expert
    score: float
    match_reasons: List[str] = []

7. Database Models:
------------------
"""SQLAlchemy database models"""
from sqlalchemy import Column, String, Text, JSON, DateTime, Integer, Float, Boolean
from sqlalchemy.sql import func
from app.utils.database import Base
import uuid

class ExpertDB(Base):
    """SQLAlchemy model for experts"""
    __tablename__ = "experts"
    __table_args__ = {"extend_existing": True}
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String, nullable=False)
    title = Column(String)
    email = Column(String)
    location = Column(String)
    organization = Column(String)
    bio = Column(Text)
    skills = Column(JSON)
    experience = Column(JSON)
    links = Column(JSON)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    # Additional fields for matching
    embedding = Column(JSON)  # Store embeddings for similarity search
    expertise_level = Column(Integer)  # 1-5 scale
    rating = Column(Float)
    total_projects = Column(Integer)
    is_verified = Column(Boolean, default=False)

8. Requirements:
---------------
fastapi==0.104.1
openai==1.35.0
pydantic==2.5.0
sqlalchemy==2.0.23

9. Utils - Embeddings:
---------------------
from sentence_transformers import SentenceTransformer
import os
from dotenv import load_dotenv

load_dotenv()

EMBEDDING_MODEL = "all-MiniLM-L6-v2"
MODEL_CACHE_DIR = os.getenv("MODEL_CACHE_DIR", "./models")

class EmbeddingGenerator:
    def __init__(self):
        os.makedirs(MODEL_CACHE_DIR, exist_ok=True)
        self.model = SentenceTransformer(
            EMBEDDING_MODEL,
            cache_folder=MODEL_CACHE_DIR
        )
    
    def generate_embedding(self, text: str):
        return self.model.encode(text).tolist()
    
    def generate_embeddings(self, texts: list):
        return self.model.encode(texts).tolist()

embedding_generator = EmbeddingGenerator()

10. Check for existing email/AI code:
------------------------------------
Email-related files:
app/utils/auth.py
app/models/user.py
app/models/expert.py
app/models/db_models.py
app/services/enhanced_search_service.py

AI-related files:

=== END OF FILE VIEWING ===
